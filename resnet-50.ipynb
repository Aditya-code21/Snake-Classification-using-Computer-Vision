{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1723401,"sourceType":"datasetVersion","datasetId":1022315}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom transformers import ResNetForImageClassification, ResNetConfig\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:40.477620Z","iopub.execute_input":"2024-10-11T09:09:40.478264Z","iopub.status.idle":"2024-10-11T09:09:48.702994Z","shell.execute_reply.started":"2024-10-11T09:09:40.478228Z","shell.execute_reply":"2024-10-11T09:09:48.702200Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data_dir = '/kaggle/input/identifying-different-breeds-of-snakes/dataset'","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:48.704564Z","iopub.execute_input":"2024-10-11T09:09:48.705015Z","iopub.status.idle":"2024-10-11T09:09:48.709324Z","shell.execute_reply.started":"2024-10-11T09:09:48.704980Z","shell.execute_reply":"2024-10-11T09:09:48.708364Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class SnakeDataset(Dataset):\n    def __init__(self, data_dir, classes, transform=None):\n        self.data_dir = data_dir\n        self.classes = classes\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []\n        \n        for class_name in classes:\n            class_dir = os.path.join(data_dir, class_name)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                self.image_paths.append(img_path)\n                self.labels.append(classes.index(class_name))\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:48.710436Z","iopub.execute_input":"2024-10-11T09:09:48.710687Z","iopub.status.idle":"2024-10-11T09:09:48.719755Z","shell.execute_reply.started":"2024-10-11T09:09:48.710658Z","shell.execute_reply":"2024-10-11T09:09:48.718838Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"classes = [\n    \"agkistrodon-contortrix\", \"agkistrodon-piscivorus\", \"coluber-constrictor\", \n    \"crotalus-atrox\", \"crotalus-horridus\", \"crotalus-ruber\", \"crotalus-scutulatus\", \n    \"crotalus-viridis\", \"diadophis-punctatus\", \"haldea-striatula\", \"heterodon-platirhinos\", \n    \"lampropeltis-californiae\", \"lampropeltis-triangulum\", \"masticophis-flagellum\", \n    \"natrix-natrix\", \"nerodia-erythrogaster\", \"nerodia-fasciata\", \"nerodia-rhombifer\", \n    \"nerodia-sipedon\", \"opheodrys-aestivus\", \"pantherophis-alleghaniensis\", \n    \"pantherophis-emoryi\", \"pantherophis-guttatus\", \"pantherophis-obsoletus\", \n    \"pantherophis-spiloides\", \"pantherophis-vulpinus\", \"pituophis-catenifer\", \n    \"rhinocheilus-lecontei\", \"storeria-dekayi\", \"storeria-occipitomaculata\", \n    \"thamnophis-elegans\", \"thamnophis-marcianus\", \"thamnophis-proximus\", \n    \"thamnophis-radix\", \"thamnophis-sirtalis\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:48.720907Z","iopub.execute_input":"2024-10-11T09:09:48.721575Z","iopub.status.idle":"2024-10-11T09:09:48.728443Z","shell.execute_reply.started":"2024-10-11T09:09:48.721533Z","shell.execute_reply":"2024-10-11T09:09:48.727316Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:48.730818Z","iopub.execute_input":"2024-10-11T09:09:48.731120Z","iopub.status.idle":"2024-10-11T09:09:48.739723Z","shell.execute_reply.started":"2024-10-11T09:09:48.731084Z","shell.execute_reply":"2024-10-11T09:09:48.739041Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"dataset = SnakeDataset(data_dir='/kaggle/input/identifying-different-breeds-of-snakes/dataset',classes=classes, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:48.740770Z","iopub.execute_input":"2024-10-11T09:09:48.741156Z","iopub.status.idle":"2024-10-11T09:09:50.122600Z","shell.execute_reply.started":"2024-10-11T09:09:48.741078Z","shell.execute_reply":"2024-10-11T09:09:50.121845Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\ntrain_dataset = torch.utils.data.Subset(dataset, train_indices)\nval_dataset = torch.utils.data.Subset(dataset, val_indices)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:50.123691Z","iopub.execute_input":"2024-10-11T09:09:50.123996Z","iopub.status.idle":"2024-10-11T09:09:50.134565Z","shell.execute_reply.started":"2024-10-11T09:09:50.123964Z","shell.execute_reply":"2024-10-11T09:09:50.133601Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:50.136094Z","iopub.execute_input":"2024-10-11T09:09:50.136468Z","iopub.status.idle":"2024-10-11T09:09:50.143260Z","shell.execute_reply.started":"2024-10-11T09:09:50.136423Z","shell.execute_reply":"2024-10-11T09:09:50.142541Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model = ResNetForImageClassification.from_pretrained('microsoft/resnet-50')","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:50.144341Z","iopub.execute_input":"2024-10-11T09:09:50.144632Z","iopub.status.idle":"2024-10-11T09:09:51.450512Z","shell.execute_reply.started":"2024-10-11T09:09:50.144601Z","shell.execute_reply":"2024-10-11T09:09:51.449754Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9a3457d84d34cd2bc4f75695748a535"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"256138304f3b4ed08585424cb835e02b"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"last_layer = model.classifier[-1]  # This assumes the last layer is a Linear layer\n\n# Check if the last layer is indeed a Linear layer\nif isinstance(last_layer, nn.Linear):\n    # Replace the last layer with a new Linear layer\n    model.classifier[-1] = nn.Linear(last_layer.in_features, len(classes))\nelse:\n    raise ValueError(\"The last layer of the classifier is not a Linear layer.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:51.451609Z","iopub.execute_input":"2024-10-11T09:09:51.451922Z","iopub.status.idle":"2024-10-11T09:09:51.459808Z","shell.execute_reply.started":"2024-10-11T09:09:51.451889Z","shell.execute_reply":"2024-10-11T09:09:51.459037Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(classes))","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:51.460934Z","iopub.execute_input":"2024-10-11T09:09:51.461295Z","iopub.status.idle":"2024-10-11T09:09:51.470323Z","shell.execute_reply.started":"2024-10-11T09:09:51.461263Z","shell.execute_reply":"2024-10-11T09:09:51.469510Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:51.471424Z","iopub.execute_input":"2024-10-11T09:09:51.473039Z","iopub.status.idle":"2024-10-11T09:09:51.755270Z","shell.execute_reply.started":"2024-10-11T09:09:51.472996Z","shell.execute_reply":"2024-10-11T09:09:51.754204Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)","metadata":{"execution":{"iopub.status.busy":"2024-10-11T09:09:51.756571Z","iopub.execute_input":"2024-10-11T09:09:51.756966Z","iopub.status.idle":"2024-10-11T09:09:51.763189Z","shell.execute_reply.started":"2024-10-11T09:09:51.756923Z","shell.execute_reply":"2024-10-11T09:09:51.762307Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=12):\n    train_losses = []\n    val_losses = []\n    val_accuracies = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        for inputs, labels in tqdm(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(inputs).logits\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        epoch_loss = running_loss / len(train_loader)\n        train_losses.append(epoch_loss)\n        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        corrects = 0\n        total = 0\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                \n                outputs = model(inputs).logits\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                \n                _, preds = torch.max(outputs, 1)\n                corrects += torch.sum(preds == labels.data)\n                total += labels.size(0)\n        \n        val_loss = val_loss / len(val_loader)\n        val_acc = corrects.double() / total\n        val_losses.append(val_loss)\n        val_accuracies.append(val_acc.item())\n        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n    \n    # Plotting the graphs\n    plt.figure(figsize=(12, 4))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Training Loss')\n    plt.plot(val_losses, label='Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training and Validation Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(val_accuracies, label='Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.title('Validation Accuracy')\n    plt.legend()\n    \n    plt.show()\n\n# Train the model\ntrain_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=12)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport torch\nfrom torchvision import transforms\n\ndef test_model_with_image(model, image_path, device):\n    # Define the same transformations used during training\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Load and transform the image\n    image = Image.open(image_path).convert('RGB')\n    image = transform(image).unsqueeze(0)  # Add batch dimension\n    image = image.to(device)\n    \n    # Set the model to evaluation mode\n    model.eval()\n    \n    # Get the model's prediction\n    with torch.no_grad():\n        outputs = model(image).logits\n        _, preds = torch.max(outputs, 1)\n    \n    # Convert the prediction to the class name\n    predicted_class = classes[preds.item()]\n    \n    print(f'The predicted class is: {predicted_class}')\n\n# Example usage\nimage_path = '/kaggle/input/identifying-different-breeds-of-snakes/dataset/heterodon-platirhinos/0154990cb5.jpg'  # Replace with your image path\ntest_model_with_image(model, image_path, device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print (model)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(),\"resnet50_snake_identification_model.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls \"/kaggle/working\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'./resnet50_snake_identification_model.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}